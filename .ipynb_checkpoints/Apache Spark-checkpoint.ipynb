{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project NoSQL: Apache Spark\n",
    "Made by Stanislas KIESGEN DE RICHTER and Gabriel PRECIGOUT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Install Java 8 or check its version\n",
    "\n",
    "Before installing Apache Spark we need to check if Java and JDK 8 are installed using the command prompt.\n",
    "\n",
    "Let's open it and check our Java versions:\n",
    "```\n",
    "C:\\Users\\gabriel>java -version\n",
    "openjdk version \"1.8.0_272\"\n",
    "OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_272-b10)\n",
    "OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.272-b10, mixed mode)\n",
    "```\n",
    "\n",
    "### 2.2. Install Python or check its version\n",
    "\n",
    "We also need to install python before we can use Apache Spark, so let's check our version:\n",
    "```\n",
    "C:\\Users\\gabriel>python\n",
    "Python 3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)] on win32\n",
    "```\n",
    "\n",
    "### 2.3. Downloading Apache Spark\n",
    "\n",
    "We need to go the following website: https://spark.apache.org/downloads.html.\n",
    "Once we dowloaded it, we need to create a folder wherever you want that we'll call Spark and extract the compressed file in there.\n",
    "When the Spark File is full, we should open the conf folder and rename the file log4j.properties.template to log4j.properties and open it with wordpad for example.\n",
    "\n",
    "Inside the log4j.properties, we'll find the following line:\n",
    "```\n",
    "# Set everything to be logged to the console\n",
    "log4j.rootCategory=INFO, console\n",
    "```\n",
    "We will change it to:\n",
    "```\n",
    "# Set everything to be logged to the console\n",
    "log4j.rootCategory=ERROR, console\n",
    "```\n",
    "This change will remove all the logs that gets prints off when we'll run commands with Spark.\n",
    "Save the file and close it.\n",
    "\n",
    "### 2.4. winutils\n",
    "\n",
    "If you're not on windows you can skip this step, otherwise it's recommended.\n",
    "You need to download winutils, you can find it here (https://github.com/steveloughran/winutils)\n",
    "This is a windows binary, Hadoop requires native libraries on Windows to work properly -that includes accessing the file:// filesystem, where Hadoop uses some Windows APIs to implement posix-like file access permissions.\n",
    "\n",
    "This is implemented in hadoop.dll and winutils.exe.\n",
    "\n",
    "Now we need to create a winutil folder at the root of our Spark folder and we can call this new folder \"winutils\", inside it we'll create another folder called \"bin\" and copy our winutils.exe here.\n",
    "\n",
    "Open the command prompt (CMD) and type the following commands:\n",
    "```\n",
    "C:\\Users\\gabki>cd C:\\Program Files (x86)\\winutils\\bin\n",
    "\n",
    "C:\\Program Files (x86)\\winutils\\bin>dir\n",
    " Le volume dans le lecteur C s’appelle Windows-SSD\n",
    " Le numéro de série du volume est D801-AF53\n",
    "\n",
    " Répertoire de C:\\Program Files (x86)\\winutils\\bin\n",
    "\n",
    "14/12/2020  22:40    <DIR>          .\n",
    "14/12/2020  22:40    <DIR>          ..\n",
    "14/12/2020  22:27           108 032 winutils.exe\n",
    "               1 fichier(s)          108 032 octets\n",
    "               2 Rép(s)  16 753 942 528 octets libres\n",
    "C:\\Program Files (x86)\\winutils\\bin>mkdir \\tmp\\hive\n",
    "C:\\Program Files (x86)\\winutils\\bin>winutils.exe ls \\tmp\\hive\n",
    "d--------- 1 DESKTOP-2KDT29C\\gabki DESKTOP-2KDT29C\\gabki 0 Dec 14 2020 \\tmp\\hive\n",
    "C:\\Program Files (x86)\\winutils\\bin>dir \\tmp\\hive\n",
    " Le volume dans le lecteur C s’appelle Windows-SSD\n",
    " Le numéro de série du volume est D801-AF53\n",
    "\n",
    " Répertoire de C:\\tmp\\hive\n",
    "\n",
    "14/12/2020  22:57    <DIR>          .\n",
    "14/12/2020  22:57    <DIR>          ..\n",
    "               0 fichier(s)                0 octets\n",
    "               2 Rép(s)  17 155 751 936 octets libres\n",
    "C:\\Program Files (x86)\\winutils\\bin>set path=%path%;\"C:\\Program Files (x86)\\winutils\\bin\"\n",
    "C:\\Program Files (x86)\\winutils\\bin>winutils.exe ls \\tmp\\hive\n",
    "drwxrwxrwx 1 DESKTOP-2KDT29C\\gabki DESKTOP-2KDT29C\\gabki 0 Dec 14 2020 \\tmp\\hive\n",
    "```\n",
    "\n",
    "### 2.5. Definition of the environment variables\n",
    "\n",
    "We need to define the environment variables and we'll be ready to use Spark!\n",
    "\n",
    "Let's define the SPARK_HOME variable with the path to our Spark folder;\n",
    "JAVA_HOME with the path to the java JDK\n",
    "HADOOP_HOME with the path to the winutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.sql(\"select 'spark' as hello \")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
